path: LLVIP # path to the dataset

train: images/train # RGB images for training (the path mast be 'images/xxx' and the IR images must be in 'image/xxx')
val: images/test # RGB images for training (the path mast be 'images/xxx' and the IR images must be in 'image/xxx')
test:  # test images (optional)

# Classes
names:
  0: person

# A pre-processed dataset suitable for direct model training is available at https://github.com/Tdzdele/LLVIP-For-Ultralytics.

# This version of the LLVIP dataset has been adapted for RGB-IR-Ultralytics, with modifications limited to annotation labels 
# and file storage format. Users are requested to cite the original dataset paper: LLVIP: A Visible-infrared Paired Dataset 
# for Low-light Vision when utilizing this data for research.

# @inproceedings{jia2021llvip,
#   title={LLVIP: A visible-infrared paired dataset for low-light vision},
#   author={Jia, Xinyu and Zhu, Chuang and Li, Minzhen and Tang, Wenqi and Zhou, Wenli},
#   booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
#   pages={3496--3504},
#   year={2021}
# }

# or

# @misc{https://doi.org/10.48550/arxiv.2108.10831,
#   doi = {10.48550/ARXIV.2108.10831}, 
#   url = {https://arxiv.org/abs/2108.10831},
#   author = {Jia, Xinyu and Zhu, Chuang and Li, Minzhen and Tang, Wenqi and Liu, Shengjie and Zhou, Wenli}, 
#   keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
#   title = {LLVIP: A Visible-infrared Paired Dataset for Low-light Vision},
#   publisher = {arXiv},
#   year = {2021},
#   copyright = {arXiv.org perpetual, non-exclusive license}
# }